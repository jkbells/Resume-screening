# Resume-screening
Natural language processing (NLP) is a widely discussed and studied subject these days. NLP, one of the oldest areas of machine learning research, is used in major fields such as machine translation speech recognition and word processing. In this Repo I’ll walk you through a Machine Learning project on NLP solved and explained with the Python programming language.

Companies often receive thousands of resumes for each job posting and employ dedicated screening officers to screen qualified candidates. In this article, I will introduce you to a machine learning project on Resume Screening with Python programming language.

# What is Resume Screening ?
Hiring the right talent is a challenge for all businesses. This challenge is magnified by the high volume of applicants if the business is labour-intensive, growing, and facing high attrition rates.
An example of such a business is that IT departments are short of growing markets. In a typical service organization, professionals with a variety of technical skills and business domain expertise are hired and assigned to projects to resolve customer issues. This task of selecting the best talent among many others is known as Resume Screening.
Typically, large companies do not have enough time to open each CV, so they use machine learning algorithms for the Resume Screening task.

# I will start this task by importing the necessary Python libraries and the dataset:
![1](https://user-images.githubusercontent.com/73393333/232815498-694adbf5-900c-463c-9095-446de0d2f8eb.png)
# Now let’s have a quick look at the categories of resumes present in the dataset:
![2](https://user-images.githubusercontent.com/73393333/232815768-438d9953-3e34-4e6f-ab1e-fbd75906aba3.png)
# Now let’s have a look at the distinct categories of resume and the number of records belonging to each category:
![3](https://user-images.githubusercontent.com/73393333/232815992-583e6acb-503c-44a6-84f5-aa3cdbbddc5e.png)
# Now let’s visualize the number of categories in the dataset:
![seaborn](https://user-images.githubusercontent.com/73393333/232816202-0bdccaef-6bd2-4d4d-b4d2-de02704e1a6d.png)
# Now let’s visualize the distribution of categories:
![category_plot](https://user-images.githubusercontent.com/73393333/232816317-eb1a8c00-af5a-4d14-8e16-2d291eb6b692.png)
# Now as we have cleared the dataset, the next task is to have a look at the Wordcloud. A Wordcloud represents the most numbers of words larger and vice versa:
![wordcloud](https://user-images.githubusercontent.com/73393333/232816517-008c1777-d301-4429-991b-36e0a788802d.png)
# Now let’s train the model and print the classification report:
![0](https://user-images.githubusercontent.com/73393333/232817836-1e50571f-7eaf-4279-a2b5-68eebcac5b87.png)
![5](https://user-images.githubusercontent.com/73393333/232816833-80f2f67d-3b20-4d9e-9a00-d65f7a1fd4bb.png)
